# Compositional Bias Control in Large Language Models
# Requirements for reproducing experiments

# Core dependencies
torch>=2.0.0
transformers>=4.35.0
accelerate>=0.24.0
datasets>=2.14.0

# Fine-tuning and adaptation
peft>=0.7.0  # For LoRA
trl>=0.7.4   # For DPO training

# Memory optimization
bitsandbytes>=0.41.0

# API clients (for baselines)
openai>=1.0.0
together>=0.2.0

# Data processing
pandas>=2.0.0
numpy>=1.24.0
scikit-learn>=1.3.0

# Analysis and visualization
matplotlib>=3.7.0
seaborn>=0.12.0
scipy>=1.11.0

# Utilities
python-dotenv>=1.0.0
tqdm>=4.65.0

# Optional: for Jupyter notebooks
# jupyter>=1.0.0
# ipykernel>=6.25.0

# Installation notes:
# 1. For GPU support, install PyTorch with CUDA:
#    pip install torch --index-url https://download.pytorch.org/whl/cu118
# 
# 2. For prompt-only and gen-filter experiments (no GPU):
#    pip install openai together pandas python-dotenv
#
# 3. For full fine-tuning experiments (GPU required):
#    pip install -r requirements.txt
#
# 4. For analysis only:
#    pip install pandas numpy matplotlib seaborn scipy scikit-learn

