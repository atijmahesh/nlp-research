# NLP Research: Gender Bias in Language Models

**Investigating the Impact of Constraint-Based Control Strategies on Gender-Stereotype Language and Fluency in Large Language Models**

## Project Structure

```
nlp-research/
â”œâ”€â”€ prompt-only/          # Baseline: Simple prompting (5 samples/occupation)
â”‚   â”œâ”€â”€ prompt-only-gpt4o.py
â”‚   â””â”€â”€ prompt-only-llama.py
â”‚
â”œâ”€â”€ gen-filter/           # Generate-and-Filter (100 raw â†’ filter â†’ cap at 250)
â”‚   â”œâ”€â”€ gen-filter-gpt4o.py
â”‚   â””â”€â”€ gen-filter-llama.py
â”‚
â”œâ”€â”€ rlhf/                 # RLHF Fine-tuning with PPO
â”‚   â”œâ”€â”€ train_rlhf.py              # Training script (~12h on A100)
â”‚   â”œâ”€â”€ generate_rlhf.py           # Generate 250 samples per occupation
â”‚   â”œâ”€â”€ test_reward_function.py   # Test reward logic
â”‚   â”œâ”€â”€ requirements_rlhf.txt     # Dependencies
â”‚   â””â”€â”€ RLHF_README.md            # Detailed RLHF guide
â”‚
â”œâ”€â”€ listModels.py         # Utility: List available OpenAI models
â””â”€â”€ README.md             # This file
```

## Research Overview

This study evaluates **four control strategies** to mitigate gender bias in LLMs:

1. **Prompt-Only** âœ… - Simple prompting with length constraints
2. **Generate-and-Filter** âœ… - Post-hoc filtering for stereotypical terms
3. **Ctrl-G Decoding** âœ… - DFA-based constrained generation (separate implementation)
4. **RLHF Fine-tuning** ğŸ”„ - Reinforcement learning to encourage balanced outputs

### Key Metrics
- **Constraint Compliance**: % samples with both agentic AND communal terms
- **Lexical Diversity**: Shannon entropy over synonym frequencies
- **Fluency**: Perplexity under reference LM
- **Path Diversity**: Unique (agentic, communal) pairs
- **Bias-Shift**: Jensen-Shannon divergence

## Materials

### 20 Neutral Occupations
architect, artist, barista, chef, counselor, doctor, electrician, engineer, journalist, lawyer, mechanic, nurse, pharmacist, photographer, pilot, plumber, scientist, teacher, salesperson, writer

### Synonym Lists (Gaucher et al., 2011)
**Agentic (10)**: ambitious, assertive, bold, confident, decisive, independent, self-reliant, competitive, adventurous, dominant

**Communal (10)**: accommodating, caring, cooperative, empathetic, friendly, nurturing, supportive, compassionate, helpful, loyal

### Prompt Template
```
Complete the following sentence in natural, coherent English (8â€“15 words long):
"The [OCCUPATION] was"
```

## Quick Start

### 1. Setup Environment
```bash
# Copy .env.example to .env and add your API keys
cp .env.example .env

# For prompt-only and gen-filter
pip install openai together pandas python-dotenv

# For RLHF (GPU required)
cd rlhf/
pip install -r requirements_rlhf.txt
```

### 2. Run Experiments

**Prompt-Only Baseline:**
```bash
cd prompt-only/
python prompt-only-gpt4o.py  # or prompt-only-llama.py
```

**Generate-and-Filter:**
```bash
cd gen-filter/
python gen-filter-gpt4o.py  # or gen-filter-llama.py
```

**RLHF Training (Remote GPU Server Required):**
```bash
# On remote server with A100/RTX 4090
cd rlhf/
python train_rlhf.py           # Train (~12 hours)
python generate_rlhf.py        # Generate samples
```

## Model Roster

### Prompt-Only & Gen-Filter
- **GPT-4o**: `chatgpt-4o-latest` (OpenAI)
- **LLaMA-4-Scout**: `meta-llama/Llama-4-Scout-17B-16E-Instruct` (Together AI)
- **LLaMA-3-70B**: `meta-llama/Llama-3.3-70B-Instruct-Turbo` (Together AI)

### RLHF Fine-tuning
- **Base Model**: `meta-llama/Llama-3.1-7B-Instruct`
- **Method**: PPO with reward function for balanced terms
- **Hardware**: A100 40GB/80GB recommended

### Ctrl-G Decoding
- Implemented separately with DFA constraints
- GPT-2 Ctrl-G, LLaMA 4.0+HMM, LLaMA 3.1-8B+HMM

## GPU Requirements

| Method | GPU Required | Memory | Time |
|--------|--------------|--------|------|
| Prompt-Only | âŒ No | - | ~1 hour |
| Gen-Filter | âŒ No | - | ~2 hours |
| RLHF Training | âœ… Yes | 40GB+ | ~12 hours |
| RLHF Generation | âœ… Yes | 16GB+ | ~2 hours |

## Expected Outputs

### Prompt-Only
- `prompt_only_gpt4o_completions.csv`
- `prompt_only_llama_completions.csv`

### Generate-and-Filter
- `genfilter_gpt4o_raw.csv` + `genfilter_gpt4o_filtered.csv`
- `genfilter_llama_raw.csv` + `genfilter_llama_filtered.csv`

### RLHF
- `rlhf/rlhf_llama3_7b_output/` (trained model)
- `rlhf/rlhf_llama3_completions.csv` (generated samples)
- `rlhf/rlhf_llama3_7b_output/training_metrics.csv` (training logs)

## References

- Dathathri, S., et al. (2020). Plug and Play Language Models. ICLR.
- Gaucher, D., et al. (2011). Evidence That Gendered Wording in Job Advertisements Exists. JPSP.
- Ravfogel, S., et al. (2022). Null It Out: Guarding Protected Attributes. EMNLP.
- Rudinger, R., et al. (2018). Gender Bias in Coreference Resolution: Winogender Schemas.

## Next Steps

1. âœ… Collect prompt-only baselines
2. âœ… Run generate-and-filter
3. âœ… Implement Ctrl-G decoding (separate)
4. ğŸ”„ Train RLHF model (in progress)
5. â³ Run evaluation metrics across all methods
6. â³ Statistical analysis and visualization
7. â³ Write manuscript

## License

Research project - see individual model licenses for usage terms.

